{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1PboKL_ucpJ9_GrYD9kn1PpZdL6oNCDLV",
      "authorship_tag": "ABX9TyNPZCEbOxHGSvjz421uOhsA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HeningWang/numpyro_adjective_modelling/blob/main/mix_pyro_slider_MCMC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import modules and dependencies\n"
      ],
      "metadata": {
        "id": "SerJv4ReACJE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "er5zrD9J_0zX",
        "outputId": "7c319f67-a731-4c0a-9c7d-5a0d6f8bab5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyro-ppl\n",
            "  Downloading pyro_ppl-1.8.5-py3-none-any.whl (732 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/732.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m732.5/732.5 kB\u001b[0m \u001b[31m38.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.10/dist-packages (from pyro-ppl) (1.22.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from pyro-ppl) (3.3.0)\n",
            "Collecting pyro-api>=0.1.1 (from pyro-ppl)\n",
            "  Downloading pyro_api-0.1.2-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: torch>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from pyro-ppl) (2.0.1+cu118)\n",
            "Requirement already satisfied: tqdm>=4.36 in /usr/local/lib/python3.10/dist-packages (from pyro-ppl) (4.65.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.1->pyro-ppl) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.1->pyro-ppl) (4.6.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.1->pyro-ppl) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.1->pyro-ppl) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.1->pyro-ppl) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.1->pyro-ppl) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=2.0.1->pyro-ppl) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=2.0.1->pyro-ppl) (16.0.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.0.1->pyro-ppl) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.0.1->pyro-ppl) (1.3.0)\n",
            "Installing collected packages: pyro-api, pyro-ppl\n",
            "Successfully installed pyro-api-0.1.2 pyro-ppl-1.8.5\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for numpyro (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting funsor\n",
            "  Downloading funsor-0.4.5-py3-none-any.whl (174 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m174.9/174.9 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting makefun (from funsor)\n",
            "  Downloading makefun-1.15.1-py2.py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: multipledispatch in /usr/local/lib/python3.10/dist-packages (from funsor) (0.6.0)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.10/dist-packages (from funsor) (1.22.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from funsor) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from funsor) (4.6.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from multipledispatch->funsor) (1.16.0)\n",
            "Installing collected packages: makefun, funsor\n",
            "Successfully installed funsor-0.4.5 makefun-1.15.1\n"
          ]
        }
      ],
      "source": [
        "!pip install pyro-ppl\n",
        "!pip install -q numpyro@git+https://github.com/pyro-ppl/numpyro\n",
        "!pip install funsor"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/HeningWang/numpyro_adjective_modelling.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WrRWkq5ODRQx",
        "outputId": "b28e72a3-e08e-4781-ac01-bceabdb19526"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'numpyro_adjective_modelling'...\n",
            "remote: Enumerating objects: 28, done.\u001b[K\n",
            "remote: Counting objects:   3% (1/28)\u001b[K\rremote: Counting objects:   7% (2/28)\u001b[K\rremote: Counting objects:  10% (3/28)\u001b[K\rremote: Counting objects:  14% (4/28)\u001b[K\rremote: Counting objects:  17% (5/28)\u001b[K\rremote: Counting objects:  21% (6/28)\u001b[K\rremote: Counting objects:  25% (7/28)\u001b[K\rremote: Counting objects:  28% (8/28)\u001b[K\rremote: Counting objects:  32% (9/28)\u001b[K\rremote: Counting objects:  35% (10/28)\u001b[K\rremote: Counting objects:  39% (11/28)\u001b[K\rremote: Counting objects:  42% (12/28)\u001b[K\rremote: Counting objects:  46% (13/28)\u001b[K\rremote: Counting objects:  50% (14/28)\u001b[K\rremote: Counting objects:  53% (15/28)\u001b[K\rremote: Counting objects:  57% (16/28)\u001b[K\rremote: Counting objects:  60% (17/28)\u001b[K\rremote: Counting objects:  64% (18/28)\u001b[K\rremote: Counting objects:  67% (19/28)\u001b[K\rremote: Counting objects:  71% (20/28)\u001b[K\rremote: Counting objects:  75% (21/28)\u001b[K\rremote: Counting objects:  78% (22/28)\u001b[K\rremote: Counting objects:  82% (23/28)\u001b[K\rremote: Counting objects:  85% (24/28)\u001b[K\rremote: Counting objects:  89% (25/28)\u001b[K\rremote: Counting objects:  92% (26/28)\u001b[K\rremote: Counting objects:  96% (27/28)\u001b[K\rremote: Counting objects: 100% (28/28)\u001b[K\rremote: Counting objects: 100% (28/28), done.\u001b[K\n",
            "remote: Compressing objects: 100% (22/22), done.\u001b[K\n",
            "remote: Total 28 (delta 7), reused 21 (delta 5), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (28/28), 773.22 KiB | 3.96 MiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "from IPython.display import set_matplotlib_formats\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "from jax import random, vmap\n",
        "from jax.scipy.special import logsumexp\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import math\n",
        "\n",
        "import numpyro\n",
        "from numpyro.diagnostics import hpdi\n",
        "import numpyro.distributions as dist\n",
        "from numpyro import handlers\n",
        "from numpyro.infer import MCMC, NUTS\n",
        "\n",
        "plt.style.use(\"bmh\")\n",
        "if \"NUMPYRO_SPHINXBUILD\" in os.environ:\n",
        "    set_matplotlib_formats(\"svg\")\n",
        "\n",
        "assert numpyro.__version__.startswith(\"0.12.1\")"
      ],
      "metadata": {
        "id": "gP0GJuTZDUrU"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/numpyro_adjective_modelling')"
      ],
      "metadata": {
        "id": "omYXIzcFAoZn"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some helper functions:"
      ],
      "metadata": {
        "id": "4oPM8Sl21PdP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mutate the dataset to include the states of the objects\n",
        "# ... states are independent variables for models\n",
        "\n",
        "def extract_states(line):\n",
        "    states = []\n",
        "    for i in range(6):\n",
        "      color = 1 if line[10 + i] == \"blue\" else 0\n",
        "      form = 1 if line[16 + i] == \"circle\" else 0\n",
        "      new_obj = (line[4 + i], color, form)\n",
        "      states.append(new_obj)\n",
        "    return jnp.array(states)\n",
        "\n",
        "\n",
        "# Transform/rescale slider value from range 0 to 100 to 0 to 1\n",
        "# ... in order to match predicted probability from models\n",
        "\n",
        "def transformation_data(slider_value, link = None):\n",
        "    if link == \"identity\":\n",
        "      slider_value = jnp.clip(slider_value, 0, 100)\n",
        "      transformed_prob = slider_value / 100\n",
        "    elif link == \"logit\":\n",
        "        transformed_prob = 1 / (1 + math.exp(-slider_value))\n",
        "    return transformed_prob\n",
        "\n",
        "def link_function(x, param = 1):\n",
        "    return 1 / (1 + jnp.exp(param * -(x - 0.5)))\n",
        "\n",
        "def compute_alpha_beta_concentration(mu, v):\n",
        "    alpha = mu * v\n",
        "    beta = (1 - mu) * v\n",
        "    return alpha, beta\n",
        "\n",
        "def Marginal(fn):\n",
        "    return memoize(lambda *args: HashingMarginal(Search(fn).run(*args)))\n",
        "\n",
        "def plot_dist(d, ax=None):\n",
        "    support = d.enumerate_support()\n",
        "    data = [d.log_prob(s).exp().item() for s in d.enumerate_support()]\n",
        "    names = list(map(str, support))\n",
        "\n",
        "    if ax is None:\n",
        "        ax = plt.subplot(111)\n",
        "\n",
        "    width = 0.3\n",
        "    bins = [x-width/2 for x in range(1, len(data) + 1)]\n",
        "    ax.bar(bins,data,width=width)\n",
        "    ax.set_xticks(list(range(1, len(data) + 1)))\n",
        "    ax.set_xticklabels(names, rotation=45, rotation_mode=\"anchor\", ha=\"right\")\n",
        "\n",
        "def get_results(posterior):\n",
        "    results = {}\n",
        "    support = posterior.enumerate_support()\n",
        "    data = [posterior.log_prob(s).exp().item() for s in posterior.enumerate_support()]\n",
        "    results[\"support\"] = support\n",
        "    results[\"probs\"] = data\n",
        "    return results\n",
        "\n",
        "def normalize(arr, axis=1):\n",
        "    \"\"\"\n",
        "    Normalize arr along axis\n",
        "    \"\"\"\n",
        "    return arr / arr.sum(axis, keepdims=True)"
      ],
      "metadata": {
        "id": "H1FHnweD1OrB"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import dataset\n",
        "dataset_url = \"/content/numpyro_adjective_modelling/dataset/dataset_slider.csv\"\n",
        "df = pd.read_csv(dataset_url)\n",
        "\n",
        "# subset data to only include combination dimension_color\n",
        "df = df[df['combination'] == 'dimension_color']\n",
        "df.reset_index(inplace=True, drop=True)\n",
        "\n",
        "# Mutate the dataset to include the states of the objects\n",
        "df_experiment = df.copy()\n",
        "df_experiment[\"states\"] = df_experiment.apply(lambda row: extract_states(row), axis=1)\n",
        "#print(df_experiment.prefer_first_1st.describe())\n",
        "\n",
        "df_experiment.prefer_first_1st = jnp.clip(df_experiment.prefer_first_1st.to_numpy(), 0, 100)\n",
        "df_experiment.prefer_first_1st = df_experiment.prefer_first_1st/100\n",
        "print(df_experiment.prefer_first_1st.describe())\n"
      ],
      "metadata": {
        "id": "kJQMF7ayDjy6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3bcbe8f6-642f-4036-c15a-79dcdc6a0695"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:jax._src.xla_bridge:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "count    3166.000000\n",
            "mean        0.704643\n",
            "std         0.380797\n",
            "min         0.000000\n",
            "25%         0.500000\n",
            "50%         0.920000\n",
            "75%         1.000000\n",
            "max         1.000000\n",
            "Name: prefer_first_1st, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# split the dataset into training and test sets\n",
        "#train, test = train_test_split(df_experiment, test_size=0.99, random_state=42)\n",
        "\n",
        "# use the whole dataset as training set\n",
        "train = df_experiment\n",
        "\n",
        "print(train.shape)\n",
        "\n",
        "states_train = jnp.stack([cell for cell in train.states])\n",
        "empirical_train = jnp.array(train.prefer_first_1st.to_numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FCJWfPCrlOzl",
        "outputId": "c404f5f0-b7af-43c1-f2c3-13e8fd7e4eeb"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3166, 27)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_threshold_kp(current_state_prior, k=0.5):\n",
        "    objs = current_state_prior\n",
        "    #measures_array = jnp.sort([x[1] for obj in objs for x in obj if x[0] == 'size'])\n",
        "    min_val = jnp.min(objs)\n",
        "    max_val = jnp.max(objs)\n",
        "    threshold = max_val - k * (max_val - min_val)\n",
        "    return threshold\n",
        "\n",
        "def adjMeaning(word, obj, current_state_prior, color_semvalue=0.98, form_semvalue=0.98, wf=0.6, k=0.5):\n",
        "    colors = [1]  # Specify the color values\n",
        "    sizes = [0]  # Specify the size values\n",
        "\n",
        "    if word == 1:\n",
        "        return numpyro.sample(\"color\", numpyro.distributions.Bernoulli(color_semvalue)) if word == obj[1] else numpyro.sample(\"color\", numpyro.distributions.Bernoulli(1 - color_semvalue))\n",
        "    elif word == 0:\n",
        "        threshold = get_threshold_kp(current_state_prior, k)\n",
        "        size = obj[0]\n",
        "        prob_big = 1 - dist.Normal(size - threshold, wf * jnp.sqrt(size ** 2 + threshold ** 2)).cdf(jnp.array([0.0]))\n",
        "        return numpyro.sample(\"size\", numpyro.distributions.Bernoulli(prob_big))\n"
      ],
      "metadata": {
        "id": "Eesz2uXtq-_9"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage for meaning function\n",
        "states = jnp.array([[10., 1., 1.],\n",
        "                   [3., 1., 1.],\n",
        "                   [3., 1., 1.],\n",
        "                   [3., 1., 0.],\n",
        "                   [3., 1., 0.],\n",
        "                   [3., 0., 1.]], dtype=jnp.float32)\n",
        "\n",
        "word = 0 # Example word, 0 for size\n",
        "obj = states[5]  # Example object from states\n",
        "\n",
        "# Example prior values\n",
        "color_semvalue = 0.98\n",
        "form_semvalue = 0.98\n",
        "wf = 0.6\n",
        "k = 0.5\n",
        "\n",
        "states[0][1]\n",
        "#get_threshold_kp(states)\n",
        "# Call the meaning function\n",
        "with handlers.seed(rng_seed=27):\n",
        " meaning = adjMeaning(word, obj, states, color_semvalue, form_semvalue, wf, k)\n",
        "\n",
        "print(meaning)\n",
        "print(obj)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R9t3pqtIrBwE",
        "outputId": "69d8dfc0-60fe-4c33-fa9a-eb76f614395f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\n",
            "[3. 0. 1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "utterances = jnp.array([\n",
        "    [0],\n",
        "    [1]\n",
        "    ])\n",
        "\n",
        "def utterance_prior(bias=1):\n",
        "    probs = jnp.array([bias,1])/(bias+1)\n",
        "    n = numpyro.sample(\"utterance_index\", dist.Categorical(probs=probs),infer={\"enumerate\": \"parallel\"})\n",
        "    return n\n",
        "\n",
        "def state_prior(states):\n",
        "    length = len(states)\n",
        "    n = numpyro.sample(\"state\", dist.Categorical(probs=jnp.ones(length) / length))\n",
        "    return states[n]"
      ],
      "metadata": {
        "id": "uwhOjsAvGHKU"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def literal_listener(states, color_semvalue = 0.98, form_semvalue = 0.98, wf = 0.6, k = 0.5):\n",
        "  probs_blue = jnp.where((1. == states[:, 1]), color_semvalue, 1 - color_semvalue)\n",
        "  threshold = get_threshold_kp(states, k)\n",
        "  probs_big = jnp.array([1 - dist.Normal(obj[0] - threshold, wf * jnp.sqrt(obj[0] ** 2 + threshold ** 2)).cdf(0.0) for obj in states])\n",
        "  probs = normalize(jnp.array([probs_big,probs_blue]))\n",
        "  return probs\n",
        "\n",
        "\n",
        "def speaker(states, alpha = 1, bias = 1, color_semvalue = 0.98, form_semvalue = 0.98, wf = 0.6, k = 0.5):\n",
        "  listener = literal_listener(states, color_semvalue, form_semvalue,wf,k)\n",
        "  bias_weights = jnp.array([0, 1]) * bias\n",
        "  util_speaker = jnp.log(jnp.transpose(listener)) - bias_weights\n",
        "  softmax_result = jax.nn.softmax(util_speaker)\n",
        "  return softmax_result[0][0]\n"
      ],
      "metadata": {
        "id": "kbsnwEJK3OS7"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index = 14\n",
        "\n",
        "states_example = df_experiment.iloc[index, df_experiment.columns.get_loc(\"states\")]\n",
        "condition = df_experiment.iloc[index, df_experiment.columns.get_loc(\"conditions\")]\n",
        "distribution = df_experiment.iloc[index, df_experiment.columns.get_loc(\"sharpness\")]\n",
        "preference = df_experiment.iloc[index, df_experiment.columns.get_loc(\"prefer_first_1st\")]\n",
        "print(states_example)\n",
        "print(condition + \" \" + distribution)\n",
        "print(preference)\n",
        "print(f\"literal listener: {literal_listener(states_example)}\")\n",
        "model_speaker = speaker(states_example, bias=0)\n",
        "print(f\"model_prediction: {model_speaker}\")\n",
        "print(f\"speaker: {model_speaker}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ernd7aLWKOsX",
        "outputId": "fb9d0ee2-abfa-46f2-dca0-807609c0d71e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 9.  1.  1.]\n",
            " [10.  0.  1.]\n",
            " [10.  0.  1.]\n",
            " [10.  0.  1.]\n",
            " [10.  0.  0.]\n",
            " [ 4.  0.  1.]]\n",
            "zrdc blurred\n",
            "0.98\n",
            "literal listener: [[0.17540349 0.18264773 0.18264773 0.18264773 0.18264773 0.09400556]\n",
            " [0.90740746 0.01851852 0.01851852 0.01851852 0.01851852 0.01851852]]\n",
            "model_prediction: 0.1619890332221985\n",
            "speaker: 0.1619890332221985\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qc_L0_P4BWVA"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorized_speaker = jax.vmap(speaker, in_axes=(0,None,None,None,None,None,None))\n",
        "model_prob = vectorized_speaker(states_train, 1,1,0.5,0.5,0.5,0.5)\n",
        "print(model_prob)\n",
        "slider_predict = jax.vmap(link_function, in_axes = (0,None))(model_prob,20)\n",
        "\n",
        "slider_predict = jnp.clip(slider_predict, 1e-5, 1 - 1e-5)\n",
        "print(slider_predict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H86DExRXBG0A",
        "outputId": "0a45f9fa-d5fb-40f6-984b-f62526d5fa59"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.7527358  0.8800761  0.75607145 ... 0.76912326 0.802139   0.81604856]\n",
            "[0.9936613  0.9995005  0.9940679  ... 0.99542457 0.9976306  0.99820507]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define the conditioned model for MCMC\n",
        "vectorized_speaker = jax.vmap(speaker, in_axes=(0,None,None,None,None,None,None))\n",
        "\n",
        "def model_inc_utt_parallel_normal(states = None, data = None):\n",
        "    gamma = numpyro.sample(\"gamma\", dist.HalfNormal(5))\n",
        "    color_semvalue = numpyro.sample(\"color_semvalue\", dist.Uniform(0, 1))\n",
        "    form_semvalue = color_semvalue\n",
        "    k = numpyro.sample(\"k\", dist.Uniform(0, 1))\n",
        "    wf = 0.5\n",
        "    bias = numpyro.sample(\"bias\", dist.HalfNormal(5))\n",
        "    steepness = numpyro.sample(\"steepness\", dist.HalfNormal(0.5))\n",
        "    sigma = numpyro.sample(\"sigma\", dist.Uniform(0,1))\n",
        "\n",
        "    with numpyro.plate(\"data\",len(states)):\n",
        "      model_prob = vectorized_speaker(states_train, gamma, bias, color_semvalue, form_semvalue, wf, k)\n",
        "      slider_predict = jax.vmap(link_function, in_axes = (0,None))(model_prob, steepness)\n",
        "      slider_predict = jnp.clip(slider_predict, 1e-5, 1 - 1e-5)\n",
        "      obs = jnp.clip(data, 1e-5, 1 - 1e-5)\n",
        "      numpyro.sample(\"obs\", dist.TruncatedNormal(slider_predict, sigma, low = 0, high = 1), obs=obs) # use this for inference\n",
        "    #pyro.sample(\"obs_{}\".format(i), dist.Beta(alpha,beta)) # use this for prior predictive\n"
      ],
      "metadata": {
        "id": "prbxURKGDQyo"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define the conditioned model for MCMC\n",
        "def model_inc_utt_serial_beta(states, data):\n",
        "    gamma = numpyro.sample(\"gamma\", dist.HalfNormal(5))\n",
        "    color_semvalue = numpyro.sample(\"color_semvalue\", dist.Uniform(0, 1))\n",
        "    form_semvalue = color_semvalue\n",
        "    k = numpyro.sample(\"k\", dist.Uniform(0, 1))\n",
        "    wf = 0.5\n",
        "    bias = numpyro.sample(\"bias\", dist.HalfNormal(5))\n",
        "    steepness = numpyro.sample(\"steepness\", dist.HalfNormal(0.5))\n",
        "    v = numpyro.sample(\"v\", dist.Uniform(1e-5,5))\n",
        "    for i in range(len(data)):\n",
        "        model = speaker(states[i], gamma, bias, color_semvalue, form_semvalue, wf, k)\n",
        "        model_prob = model[0][0]\n",
        "        slider_predict = link_function(model_prob, link = \"rapidlogit\", param = steepness)\n",
        "        slider_predict = jnp.clip(slider_predict, 1e-5, 1 - 1e-5)\n",
        "        obs = jnp.clip(data[i], 1e-5, 1 - 1e-5)\n",
        "        alpha, beta = compute_alpha_beta_concentration(slider_predict, v)\n",
        "        numpyro.sample(\"obs_{}\".format(i), dist.Beta(alpha,beta), obs=obs) # use this for inference\n",
        "        #pyro.sample(\"obs_{}\".format(i), dist.Beta(alpha,beta)) # use this for prior predictive\n"
      ],
      "metadata": {
        "id": "_JaQwhEnKdHc"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define the MCMC kernel and the number of samples\n",
        "rng_key = random.PRNGKey(0)\n",
        "rng_key, rng_key_ = random.split(rng_key)\n",
        "\n",
        "kernel = NUTS(model_inc_utt_parallel_normal, target_accept_prob=0.8)\n",
        "mcmc_inc = MCMC(kernel, num_warmup=1000,num_samples=1000)\n",
        "mcmc_inc.run(rng_key_, states_train, empirical_train)\n",
        "\n",
        "# print the summary of the posterior distribution\n",
        "mcmc_inc.print_summary()\n",
        "\n",
        "# Get the MCMC samples and convert to a DataFrame\n",
        "posterior_inc = mcmc_inc.get_samples()\n",
        "df_inc = pd.DataFrame(posterior_inc)\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "df_inc.to_csv('posterior_inc_utt_slider.csv', index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-0J580lAKvIZ",
        "outputId": "b545dd54-6d98-4dcb-e768-ad28c8bb4cba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "sample: 100%|██████████| 2000/2000 [01:51<00:00, 17.92it/s, 7 steps of size 4.43e-01. acc. prob=0.91]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                      mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
            "            bias      7.39      2.62      7.16      3.57     12.00    726.39      1.00\n",
            "  color_semvalue      0.42      0.29      0.40      0.00      0.84    759.24      1.00\n",
            "           gamma      3.90      3.08      3.24      0.00      8.25    978.92      1.00\n",
            "               k      0.48      0.28      0.47      0.03      0.90   1075.56      1.00\n",
            "       steepness      5.85      0.27      5.85      5.45      6.38    851.08      1.00\n",
            "               v      0.63      0.02      0.63      0.60      0.67   1131.21      1.00\n",
            "\n",
            "Number of divergences: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6iviZKfv9Hb1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}