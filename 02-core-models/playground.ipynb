{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "#from IPython.display import set_matplotlib_formats\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import random, vmap\n",
    "from jax.scipy.special import logsumexp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import math\n",
    "import scipy\n",
    "\n",
    "import numpyro\n",
    "from numpyro.diagnostics import hpdi\n",
    "import numpyro.distributions as dist\n",
    "from numpyro import handlers\n",
    "from numpyro.infer import MCMC, NUTS\n",
    "from sklearn.model_selection import train_test_split\n",
    "numpyro.set_platform(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Platform 'METAL' is experimental and not all JAX functionality may be correctly supported!\n",
      "2024-07-15 15:03:20.254601: W pjrt_plugin/src/mps_client.cc:563] WARNING: JAX Apple GPU support is experimental and not all JAX functionality is correctly supported!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M2 Pro\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n",
      "start: [1. 0. 0. 0. 0.]\n",
      "end: [0. 1. 0. 0. 0.]\n",
      "color: [0. 0. 1. 0. 0.]\n",
      "form: [0. 0. 0. 1. 0.]\n",
      "size: [0. 0. 0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "# Try to implement categories as one hot encoding\n",
    "# start, end, color, form, size\n",
    "start = jnp.array([1, 0, 0, 0, 0])\n",
    "end = jnp.array([0, 1, 0, 0, 0])\n",
    "color = jnp.array([0, 0, 1, 0, 0])\n",
    "form = jnp.array([0, 0, 0, 1, 0])\n",
    "size = jnp.array([0, 0, 0, 0, 1])\n",
    "\n",
    "vocab = [\"start\", \"end\", \"color\", \"form\", \"size\"]\n",
    "\n",
    "# Define the vocabulary\n",
    "vocab = ['start', 'end', 'color', 'form', 'size']\n",
    "\n",
    "# Create one-hot vectors for each vocabulary item\n",
    "vocab_size = len(vocab)\n",
    "one_hot_vectors = jnp.eye(vocab_size)\n",
    "\n",
    "# Map each word to its one-hot vector\n",
    "vocab_to_one_hot = {word: one_hot_vectors[i] for i, word in enumerate(vocab)}\n",
    "\n",
    "# Display the one-hot vectors\n",
    "for word, one_hot in vocab_to_one_hot.items():\n",
    "    print(f\"{word}: {one_hot}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'color': Array([1., 0., 0., 0., 0.], dtype=float32), 'form': Array([0., 1., 0., 0., 0.], dtype=float32), 'size': Array([0., 0., 1., 0., 0.], dtype=float32), 'start': Array([0., 0., 0., 1., 0.], dtype=float32), 'end': Array([0., 0., 0., 0., 1.], dtype=float32)}\n",
      "{'start': Array([0.33333334, 0.33333334, 0.33333334, 0.        , 0.        ],      dtype=float32), 'firstnode': Array([0.25, 0.25, 0.25, 0.  , 0.25], dtype=float32), 'secondnode': Array([0.25, 0.25, 0.25, 0.  , 0.25], dtype=float32), 'end': Array([0, 0, 0, 0, 1], dtype=int32)}\n"
     ]
    }
   ],
   "source": [
    "# Define a simple language model using one hot vectors\n",
    "# Start-firstnode-secondnode-end\n",
    "# At start, equal probability of color, form, size followed by start symbol\n",
    "# At first node, equal probability of color, form, size and end symbol\n",
    "# At second node, equal probability of color, form, size and end symbol\n",
    "# At end, only end symbol\n",
    "\n",
    "vocab = ['color', 'form', 'size', 'SOS', 'EOS']\n",
    "\n",
    "def vocab_to_one_hot(vocab):\n",
    "    \"\"\"\n",
    "    Input: vocab - list of words in the vocabulary\n",
    "    Output: dictionary mapping each word to its one-hot vector\n",
    "    \"\"\"\n",
    "    # Create one-hot vectors for each vocabulary item\n",
    "    vocab_size = len(vocab)\n",
    "    one_hot_vectors = jnp.eye(vocab_size)\n",
    "    \n",
    "    # Map each word to its one-hot vector\n",
    "    vocab_to_one_hot = {word: one_hot_vectors[i] for i, word in enumerate(vocab)}\n",
    "    \n",
    "    return vocab_to_one_hot\n",
    "\n",
    "partial_input = \"\"\n",
    "def PCFG(partial_input, node):\n",
    "    # Define the recursive end state\n",
    "    if node == 'end':\n",
    "        return vocab_to_one_hot['EOS']\n",
    "    else:\n",
    "        PCFG(partial_input, node)\n",
    "    \n",
    "    pass\n",
    "    # Define the transition probabilities\n",
    "\n",
    "\n",
    "\n",
    "def language_model(vocab):\n",
    "    \"\"\"\n",
    "    Input: vocab - dictionary of one hot vectors for each word in the vocabulary\n",
    "    Output: prior probabilities of each full utterances\n",
    "    Function: Implement a simple PCFG language model\n",
    "    Description for the PCFG:\n",
    "    1. Starting with the SOS symbol\n",
    "    2. Equal probability of color, form, size on first node\n",
    "    3. If color is given from the first node, equal probability of form, size and EOS on second node. Same for if form or size is given\n",
    "    4. If both color and form are given from the first node, equal probability of size and EOS on third node. Same for if color and size or form and size are given\n",
    "    5. Whatever EOS is given, the sentence ends\n",
    "    \"\"\"\n",
    "    # Define vocabulary\n",
    "    \n",
    "    \n",
    "    # Create one-hot vectors for each vocabulary item\n",
    "    vocab_vectors = jnp.eye(len(vocab))\n",
    "    \n",
    "    # Map each word to its one-hot vector\n",
    "    word_to_vector = {word: vocab_vectors[i] for i, word in enumerate(vocab)}\n",
    "    \n",
    "    # Transition probabilities\n",
    "    # At start: equal probability for color, form, size\n",
    "    start_probs = jnp.array([0, 0, 0, 1, 0])\n",
    "\n",
    "    # At first node: equal probability for color, form, size, and end\n",
    "    first_node_probs = jnp.array([1/3, 1/3, 1/3, 0, 0])\n",
    "    \n",
    "    # At second node: equal probability for color, form, size, and end\n",
    "    second_node_probs = jnp.array([1/4, 1/4, 1/4, 0, 1/4])\n",
    "    \n",
    "\n",
    "    # At end: only end symbol\n",
    "    end_probs = jnp.array([0, 0, 0, 0, 1])\n",
    "    \n",
    "    # Define the transitions\n",
    "    transitions = {\n",
    "        'start': start_probs,\n",
    "        'firstnode': node_probs,\n",
    "        'secondnode': node_probs,\n",
    "        'end': end_probs\n",
    "    }\n",
    "    \n",
    "    # Return the model components\n",
    "    return word_to_vector, transitions\n",
    "\n",
    "word_to_vector, transitions = language_model()\n",
    "\n",
    "print(word_to_vector)\n",
    "print(transitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.  3.  3.  0.5 2.  3.  3.  2.  0.5 2.  2.  1.  0.5 0.5 0.5]\n",
      "[[0.16666667 0.16666667 0.16666667 0.16666667 0.16666667 0.16666667]\n",
      " [0.16666667 0.16666667 0.16666667 0.16666667 0.16666667 0.16666667]]\n"
     ]
    }
   ],
   "source": [
    "utterances = [\n",
    "    \"D\",\n",
    "    \"C\",\n",
    "    \"F\",\n",
    "    \"CD\", #CD\n",
    "    \"CF\",\n",
    "    \"DC\",\n",
    "    \"DF\",\n",
    "    \"FC\",\n",
    "    \"FD\", #FD\n",
    "    \"DCF\",\n",
    "    \"DFC\",\n",
    "    \"CDF\",\n",
    "    \"CFD\", # CFD\n",
    "    \"FCD\", # FCD\n",
    "    \"FDC\", # FDC\n",
    "    ]\n",
    "\n",
    "\n",
    "def utterance_utils(uttrances, biased=False):\n",
    "    \"\"\"\n",
    "    Input: list of utterances\n",
    "    Output: list of utils scores for each utterance\n",
    "\n",
    "    Depends on the length of utterances, assign 3 to the ones with length 1, 2 to the ones with length 2 and 1 to the ones with length 3\n",
    "    Also, allow to costumize the utils scores given the value of the utterances\n",
    "    If biased = True, assign 0.5 to \"CD, FD, CFD, FCD, FDC\", assign +1 to utterances staring with \"D\" on top of the previous rule\n",
    "    \"\"\"\n",
    "    # Calculate the utils scores based on the length of utterances\n",
    "    utils = [3 if len(utt) == 1 else 2 if len(utt) == 2 else 1 for utt in utterances]\n",
    "\n",
    "    # Customize the utils scores if biased is True\n",
    "    if biased:\n",
    "        biased_utils = [0.5 if utterances[i] == \"CD\" or \n",
    "                        utterances[i] == \"FD\" or \n",
    "                        utterances[i] == \"CFD\" \n",
    "                        or utterances[i] == \"FCD\" \n",
    "                        or utterances[i] == \"FDC\" else utils[i] for i in range(len(utterances))]\n",
    "        utils = [1 + biased_utils[i] if utterances[i].startswith(\"D\") else biased_utils[i] for i in range(len(utterances))]\n",
    "\n",
    "    utils = jnp.array(utils)\n",
    "    return utils\n",
    "    \n",
    "utils = utterance_utils(utterances, biased = True)\n",
    "print(utils)\n",
    "\n",
    "def utterance_prior(utils):\n",
    "    \"\"\"\n",
    "    Input: list of utils scores\n",
    "    Output: list of prior probabilities for each utterance\n",
    "    \"\"\"\n",
    "    prior = jnp.exp(utils) / jnp.sum(jnp.exp(utils))\n",
    "    return prior\n",
    "\n",
    "utt_prior = utterance_prior(utils)\n",
    "\n",
    "def normalize(arr, axis=1):\n",
    "    \"\"\"\n",
    "    Normalize arr along axis\n",
    "    \"\"\"\n",
    "    return arr / jnp.sum(arr, axis=axis, keepdims=True)\n",
    "\n",
    "def uniform_state_prior(nobj=6):\n",
    "    \"\"\"\n",
    "    Input: number of objects\n",
    "    Output: list of prior probabilities for each object\n",
    "    \"\"\"\n",
    "    prior=normalize(jnp.ones((2,nobj)))\n",
    "    return prior\n",
    "\n",
    "stt_prior = uniform_state_prior()\n",
    "print(stt_prior)\n",
    "\n",
    "def get_threshold_kp(states, k=0.5):\n",
    "    min_val = jnp.min(states[:,0])\n",
    "    max_val = jnp.max(states[:,0])\n",
    "    threshold = max_val - k * (max_val - min_val)\n",
    "    return threshold\n",
    "\n",
    "def get_size_semval(size,threshold,wf=0.5):\n",
    "  return 1 - dist.Normal(size - threshold, wf * jnp.sqrt(size ** 2 + threshold ** 2)).cdf(0.0)\n",
    "\n",
    "def meaning(word, states, state_prior):\n",
    "    color_semvalue = 0.9\n",
    "    form_semvalue = 0.95\n",
    "\n",
    "    if word == \"C\":\n",
    "        probs = jnp.where((1. == states[:,1]), color_semvalue, 1 - color_semvalue)\n",
    "    \n",
    "    if word == \"F\":\n",
    "        probs = jnp.where((1. == states[:,2]), form_semvalue, 1 - form_semvalue)\n",
    "\n",
    "    if word == \"D\":\n",
    "        threshold = get_threshold_kp(states, state_prior[0,:])\n",
    "        probs = jax.vmap(get_size_semval, in_axes = (0, None))(states[:,0], threshold) # Apply the meaning function for size adjective\n",
    "    \n",
    "    return probs\n",
    "        \n",
    "def incremental_literal_listener(states):\n",
    "    # C\n",
    "    probs_C = meaning(\"C\", states)\n",
    "    pass\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "XlaRuntimeError",
     "evalue": "UNKNOWN: /Users/heningwang/Documents/GitHub/numpyro_adjective_modelling/jax-metal/lib/python3.11/site-packages/numpyro/distributions/continuous.py:2049:15: error: failed to legalize operation 'chlo.erfc'\n        return ndtr(scaled)\n              ^\n/Users/heningwang/Documents/GitHub/numpyro_adjective_modelling/jax-metal/lib/python3.11/site-packages/numpyro/distributions/continuous.py:2049:15: note: see current operation: %0 = \"chlo.erfc\"(%arg0) : (tensor<6x6xf32>) -> tensor<6x6xf32>\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mXlaRuntimeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[62], line 7\u001b[0m\n\u001b[1;32m      1\u001b[0m states_manuell \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39marray([[\u001b[38;5;241m10.\u001b[39m, \u001b[38;5;241m1.\u001b[39m, \u001b[38;5;241m1.\u001b[39m],\n\u001b[1;32m      2\u001b[0m                             [\u001b[38;5;241m10.\u001b[39m, \u001b[38;5;241m1.\u001b[39m, \u001b[38;5;241m1.\u001b[39m],\n\u001b[1;32m      3\u001b[0m                             [\u001b[38;5;241m3.\u001b[39m, \u001b[38;5;241m1.\u001b[39m, \u001b[38;5;241m1.\u001b[39m],\n\u001b[1;32m      4\u001b[0m                             [\u001b[38;5;241m3.\u001b[39m, \u001b[38;5;241m1.\u001b[39m, \u001b[38;5;241m0.\u001b[39m],\n\u001b[1;32m      5\u001b[0m                             [\u001b[38;5;241m3.\u001b[39m, \u001b[38;5;241m1.\u001b[39m, \u001b[38;5;241m0.\u001b[39m],\n\u001b[1;32m      6\u001b[0m                             [\u001b[38;5;241m1.\u001b[39m, \u001b[38;5;241m0.\u001b[39m, \u001b[38;5;241m1.\u001b[39m]], dtype\u001b[38;5;241m=\u001b[39mjnp\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mmeaning\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mD\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstates_manuell\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstt_prior\u001b[49m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[0;32mIn[61], line 95\u001b[0m, in \u001b[0;36mmeaning\u001b[0;34m(word, states, state_prior)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m word \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     94\u001b[0m     threshold \u001b[38;5;241m=\u001b[39m get_threshold_kp(states, state_prior[\u001b[38;5;241m0\u001b[39m,:])\n\u001b[0;32m---> 95\u001b[0m     probs \u001b[38;5;241m=\u001b[39m \u001b[43mjax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mget_size_semval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_axes\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstates\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# Apply the meaning function for size adjective\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m probs\n",
      "    \u001b[0;31m[... skipping hidden 3 frame]\u001b[0m\n",
      "Cell \u001b[0;32mIn[61], line 81\u001b[0m, in \u001b[0;36mget_size_semval\u001b[0;34m(size, threshold, wf)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_size_semval\u001b[39m(size,threshold,wf\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m):\n\u001b[0;32m---> 81\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[43mdist\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mNormal\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mjnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcdf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/numpyro_adjective_modelling/jax-metal/lib/python3.11/site-packages/numpyro/distributions/continuous.py:2049\u001b[0m, in \u001b[0;36mNormal.cdf\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   2047\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcdf\u001b[39m(\u001b[38;5;28mself\u001b[39m, value):\n\u001b[1;32m   2048\u001b[0m     scaled \u001b[38;5;241m=\u001b[39m (value \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloc) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale\n\u001b[0;32m-> 2049\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mndtr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscaled\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/numpyro_adjective_modelling/jax-metal/lib/python3.11/site-packages/jax/_src/scipy/special.py:409\u001b[0m, in \u001b[0;36mndtr\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (jnp\u001b[38;5;241m.\u001b[39mfloat32, jnp\u001b[38;5;241m.\u001b[39mfloat64):\n\u001b[1;32m    406\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    407\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx.dtype=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m is not supported, see docstring for supported types.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    408\u001b[0m       \u001b[38;5;241m.\u001b[39mformat(dtype))\n\u001b[0;32m--> 409\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_ndtr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/numpyro_adjective_modelling/jax-metal/lib/python3.11/site-packages/jax/_src/scipy/special.py:421\u001b[0m, in \u001b[0;36m_ndtr\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    416\u001b[0m w \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m*\u001b[39m half_sqrt_2\n\u001b[1;32m    417\u001b[0m z \u001b[38;5;241m=\u001b[39m lax\u001b[38;5;241m.\u001b[39mabs(w)\n\u001b[1;32m    418\u001b[0m y \u001b[38;5;241m=\u001b[39m lax\u001b[38;5;241m.\u001b[39mselect(lax\u001b[38;5;241m.\u001b[39mlt(z, half_sqrt_2),\n\u001b[1;32m    419\u001b[0m                     dtype(\u001b[38;5;241m1.\u001b[39m) \u001b[38;5;241m+\u001b[39m lax\u001b[38;5;241m.\u001b[39merf(w),\n\u001b[1;32m    420\u001b[0m                     lax\u001b[38;5;241m.\u001b[39mselect(lax\u001b[38;5;241m.\u001b[39mgt(w, dtype(\u001b[38;5;241m0.\u001b[39m)),\n\u001b[0;32m--> 421\u001b[0m                                     dtype(\u001b[38;5;241m2.\u001b[39m) \u001b[38;5;241m-\u001b[39m \u001b[43mlax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merfc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    422\u001b[0m                                     lax\u001b[38;5;241m.\u001b[39merfc(z)))\n\u001b[1;32m    423\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dtype(\u001b[38;5;241m0.5\u001b[39m) \u001b[38;5;241m*\u001b[39m y\n",
      "    \u001b[0;31m[... skipping hidden 17 frame]\u001b[0m\n",
      "File \u001b[0;32m~/Documents/GitHub/numpyro_adjective_modelling/jax-metal/lib/python3.11/site-packages/jax/_src/compiler.py:255\u001b[0m, in \u001b[0;36mbackend_compile\u001b[0;34m(backend, module, options, host_callbacks)\u001b[0m\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m backend\u001b[38;5;241m.\u001b[39mcompile(built_c, compile_options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m    251\u001b[0m                          host_callbacks\u001b[38;5;241m=\u001b[39mhost_callbacks)\n\u001b[1;32m    252\u001b[0m \u001b[38;5;66;03m# Some backends don't have `host_callbacks` option yet\u001b[39;00m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;66;03m# TODO(sharadmv): remove this fallback when all backends allow `compile`\u001b[39;00m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;66;03m# to take in `host_callbacks`\u001b[39;00m\n\u001b[0;32m--> 255\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuilt_c\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompile_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mXlaRuntimeError\u001b[0m: UNKNOWN: /Users/heningwang/Documents/GitHub/numpyro_adjective_modelling/jax-metal/lib/python3.11/site-packages/numpyro/distributions/continuous.py:2049:15: error: failed to legalize operation 'chlo.erfc'\n        return ndtr(scaled)\n              ^\n/Users/heningwang/Documents/GitHub/numpyro_adjective_modelling/jax-metal/lib/python3.11/site-packages/numpyro/distributions/continuous.py:2049:15: note: see current operation: %0 = \"chlo.erfc\"(%arg0) : (tensor<6x6xf32>) -> tensor<6x6xf32>\n"
     ]
    }
   ],
   "source": [
    "states_manuell = jnp.array([[10., 1., 1.],\n",
    "                            [10., 1., 1.],\n",
    "                            [3., 1., 1.],\n",
    "                            [3., 1., 0.],\n",
    "                            [3., 1., 0.],\n",
    "                            [1., 0., 1.]], dtype=jnp.float32)\n",
    "print(meaning(\"D\", states_manuell, stt_prior))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Platform 'METAL' is experimental and not all JAX functionality may be correctly supported!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M2 Pro\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n",
      "[1 1 1 9 4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-18 17:47:42.318667: W pjrt_plugin/src/mps_client.cc:563] WARNING: JAX Apple GPU support is experimental and not all JAX functionality is correctly supported!\n"
     ]
    }
   ],
   "source": [
    "import jax.numpy as jnp\n",
    "\n",
    "def encode_utterances(utterances_list):\n",
    "    \"\"\"\n",
    "    Input: list of strings of 15 categories\n",
    "    Output: jnp.array of indices\n",
    "    Given the ordering of utterances, encode the strings into indices.\n",
    "    \"\"\"\n",
    "    # Define the fixed ordering of utterances\n",
    "    utterances_order = [\n",
    "        \"D\", \"C\", \"F\", \"CD\", \"CF\", \"DC\", \"DF\",\n",
    "        \"FC\", \"FD\", \"DCF\", \"DFC\", \"CDF\", \"CFD\", \"FCD\", \"FDC\"\n",
    "    ]\n",
    "    \n",
    "    # Create a dictionary that maps each utterance to its index\n",
    "    utterance_to_index = {utterance: idx for idx, utterance in enumerate(utterances_order)}\n",
    "    \n",
    "    # Encode the input list of strings into indices\n",
    "    indices = [utterance_to_index[utterance] for utterance in utterances_list]\n",
    "    \n",
    "    # Return the indices as a jnp.array\n",
    "    return jnp.array(indices)\n",
    "\n",
    "# Example usage\n",
    "utterances = ['C', 'C', 'C', 'DCF', 'CF']\n",
    "\n",
    "encoded_indices = encode_utterances(utterances)\n",
    "print(encoded_indices)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jax-metal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
